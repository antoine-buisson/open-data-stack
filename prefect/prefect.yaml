# Welcome to your prefect.yaml file! You can use this file for storing and managing
# configuration for deploying your flows. We recommend committing this file to source
# control along with your flow code.

# Generic metadata about this project
name: prefect
prefect-version: 3.1.4

# build section allows you to manage and build docker images
build:
- prefect_docker.deployments.steps.build_docker_image:
    id: build_image
    requires: prefect-docker>=0.3.1
    image_name: prefect-main
    tag: latest
    dockerfile: Dockerfile
- prefect_docker.deployments.steps.build_docker_image:
    id: build_image_dask
    requires: prefect-docker>=0.3.1
    image_name: dask-custom
    tag: latest
    dockerfile: DockerfileDask
- prefect_docker.deployments.steps.build_docker_image:
    id: build_image_spark
    requires: prefect-docker>=0.3.1
    image_name: spark-custom
    tag: latest
    dockerfile: DockerfileSpark

# push section allows you to manage if and how this project is uploaded to remote locations
push:
# - prefect_docker.deployments.steps.push_docker_image:
#     requires: prefect-docker>=0.3.1
#     image_name: '{{ build_image.image_name }}'
#     tag: '{{ build_image.tag }}'

# pull section allows you to provide instructions for cloning this project in remote locations
pull:
- prefect.deployments.steps.set_working_directory:
    directory: /opt/prefect

# the deployments section allows you to provide configuration for deploying flows
deployments:
- name: main
  version:
  tags: []
  description:
  schedule: {}
  entrypoint: flows/main.py:my_flow
  parameters: {
    "nb_dataframes": 2,
    "n_spark_executors": 1
  }
  work_pool:
    name: default
    work_queue_name:
    job_variables:
      image: '{{ build_image.image }}'
      image_pull_policy: Never
      service_account_name: prefect-worker-sa
      finished_job_ttl: 120
  concurrency_limit:
  enforce_parameter_schema: true
  schedules: []
